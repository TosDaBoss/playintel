# Complete Column Origins Breakdown - 27 Columns in fact_game_metrics

## Where Each Column Comes From

### Script 1: `steam_to_postgres.py` (4 columns)
These are the **foundation** columns:

1. âœ… `appid` - Steam app ID *(from SteamSpy paginated API)*
2. âœ… `name` - Game name *(from SteamSpy paginated API)*
3. âœ… `created_at` - Record creation timestamp *(auto-generated by PostgreSQL)*
4. âœ… `updated_at` - Record update timestamp *(auto-generated by PostgreSQL)*

---

### Script 2: `enrich_steam_data_fast.py` (9 columns)
These come from **SteamSpy app details API**:

5. âœ… `developer` - Developer name *(from SteamSpy)*
6. âœ… `publisher` - Publisher name *(from SteamSpy)*
7. âœ… `total_owners` - Mapped from `players_forever` *(from SteamSpy)*
8. âœ… `positive_reviews` - Mapped from `positive` *(from SteamSpy)*
9. âœ… `negative_reviews` - Mapped from `negative` *(from SteamSpy)*
10. âœ… `score_rank` - SteamSpy ranking *(from SteamSpy)*
11. ðŸ”„ `avg_hours_played` - Calculated from `average_forever` *(SteamSpy gives minutes, script 3 converts to hours)*
12. ðŸ”„ `price_usd` - Calculated from `price` *(SteamSpy gives cents, script 3 converts to dollars)*
13. ðŸ”„ `initialprice_usd` - Calculated from `initialprice` *(SteamSpy gives cents, script 3 converts to dollars)*

---

### Script 3: `create_analytics_tables.py` (14 columns)
These are **calculated/derived** from the data in scripts 1 & 2:

14. âœ… `is_free` - Calculated: `price = 0`
15. âœ… `has_discount` - Calculated: `price < initialprice`
16. âœ… `discount_percentage` - Calculated: `((initialprice - price) / initialprice) * 100`
17. âœ… `price_category` - Calculated: Text category based on price range
18. âœ… `hours_per_dollar` - Calculated: `avg_hours_played / price_usd`
19. âœ… `total_reviews` - Calculated: `positive + negative`
20. âœ… `rating_percentage` - Calculated: `(positive / total_reviews) * 100`
21. âœ… `review_category` - Calculated: Text category based on rating %
22. âœ… `engagement_score` - Calculated: `avg_hours * rating * log(players)`

---

### Manual Database Schema Changes (4 columns)
These were **added manually** via SQL (not from any of your 3 scripts):

23. â“ `release_date` - *(NOT in any of your 3 scripts)*
24. â“ `genres` - *(NOT in any of your 3 scripts)*
25. â“ `categories` - *(NOT in any of your 3 scripts)*
26. â“ `median_hours_played` - *(NOT in any of your 3 scripts)*
27. â“ `ccu` - *(NOT in any of your 3 scripts)*

**These 4 columns exist in your database but are NOT populated by your current ETL pipeline!**

---

## Summary Table

| Source | Number of Columns | Column Names |
|--------|-------------------|--------------|
| **Script 1** (steam_to_postgres.py) | 4 | appid, name, created_at, updated_at |
| **Script 2** (enrich_steam_data_fast.py) | 9 | developer, publisher, total_owners (from players_forever), positive_reviews, negative_reviews, score_rank, avg_hours_played (from average_forever), price_usd (from price), initialprice_usd (from initialprice) |
| **Script 3** (create_analytics_tables.py) | 14 | is_free, has_discount, discount_percentage, price_category, hours_per_dollar, total_reviews, rating_percentage, review_category, engagement_score |
| **Manual SQL** (added outside pipeline) | 4 | release_date, genres, categories, median_hours_played, ccu |
| **TOTAL** | **27** | All columns in fact_game_metrics |

---

## The 4 Mystery Columns

These 4 columns were likely added when I helped you earlier in this session:

1. **`release_date`** - Available from Steam API
2. **`genres`** - Available from Steam API
3. **`categories`** - Available from Steam API
4. **`median_hours_played`** - Available from SteamSpy API
5. **`ccu`** - Available from SteamSpy API (peak concurrent users)

**Remember:** I ran this SQL earlier to add missing columns:

```sql
ALTER TABLE fact_game_metrics
ADD COLUMN IF NOT EXISTS release_date TEXT,
ADD COLUMN IF NOT EXISTS genres TEXT,
ADD COLUMN IF NOT EXISTS categories TEXT,
ADD COLUMN IF NOT EXISTS median_hours_played NUMERIC,
ADD COLUMN IF NOT EXISTS ccu INTEGER;
```

---

## Data Sources Recap

### From SteamSpy API (`enrich_steam_data_fast.py`):
- `players_forever` â†’ becomes `total_owners`
- `average_forever` â†’ becomes `avg_hours_played` (minutes â†’ hours)
- `price` â†’ becomes `price_usd` (cents â†’ dollars)
- `initialprice` â†’ becomes `initialprice_usd` (cents â†’ dollars)
- `positive` â†’ becomes `positive_reviews`
- `negative` â†’ becomes `negative_reviews`
- `score_rank`
- `developer`
- `publisher`

### Available but NOT fetched by your scripts:
- âŒ `median_forever` â†’ should become `median_hours_played`
- âŒ `ccu` - peak concurrent users
- âŒ `average_2weeks` - recent playtime
- âŒ `median_2weeks` - recent median playtime
- âŒ `tags` - user-generated tags

### From Steam API (NOT in your pipeline yet):
- âŒ `release_date`
- âŒ `genres`
- âŒ `categories`
- âŒ `platforms` (Windows/Mac/Linux)
- âŒ `supported_languages`
- âŒ `recommendations` count
- âŒ Many others...

---

## What Needs to Happen

### Option 1: Use your existing pipeline
Run `enrich_steam_data_fast.py` to populate the 9 columns it's responsible for:
```bash
python3 /Users/tosdaboss/enrich_steam_data_fast.py
```

This will fix `total_owners` being 0 for all games.

### Option 2: Extend your existing pipeline
Modify `enrich_steam_data_fast.py` to also fetch:
- `median_forever` (for `median_hours_played`)
- `ccu` (peak concurrent users)

Then add Steam API calls to fetch:
- `release_date`
- `genres`
- `categories`

### Option 3: Use the new ETL script I created
The `etl_steam_data.py` I created earlier fetches ALL of these fields:
```bash
python3 /Users/tosdaboss/playintel/etl_steam_data.py --update-existing --limit 10
```

This will populate all 27 columns including the 4 mystery ones.

---

## Answer to Your Question

**Q: "I currently have 27 columns in total, why does it show that the enrich steam data fast only brings in 9 columns, where are the rest of the columns coming from?"**

**A:**
- **4 columns** from `steam_to_postgres.py` (appid, name, timestamps)
- **9 columns** from `enrich_steam_data_fast.py` (SteamSpy metrics)
- **14 columns** from `create_analytics_tables.py` (calculated/derived)
- **4 columns** added manually via SQL (release_date, genres, categories, median_hours_played, ccu) - these were added when I helped you earlier but are NOT populated yet

The **4 manual columns** are the ones that are NULL right now because your existing 3-script pipeline doesn't fetch them!
